# withdrawalAnalysis

is a poorly implemented rough sketch prototype of a utility that reads data from any form of an excel file xls, or xlsx and saves the same into a database. This is usually after creating objects per row. The cells per row consist the individual fields of the object. This allows me to use JPA to persist them to mysql.The reason I say it is poorly implemented is because the number of fields the object can have is fixed. I would rather create an object with dynamic number of fields then persist it in the database. This way I do not have to adjust my fields for every project. But this project has a short timeine before it needs to be completed. There are also something like 9 worksheets with 65,000 rows each. Immediately you try anything with excel using this, excel will just stop working... So java to the rescue <br>

#UPDATE: 
Not good enough. There are 65000 rows of data on each of 9 worksheets. I spent a day trying to emulate a weak form of Yegor Bugayenko's SQL-speaking objects, running on JDBC. I am not happy with the patterns that resulted, because it feels rather unfamiliar. Bad programming is probably embedded in me. However that is not be reason why I am thinking of abandoning this project. It's just with that much data in memory, even the cache(needs work) I implemented following a certain blog, could not stop my VM from running out of memory. And then I began to form an idea. I don't really like it but it seems to be the only way. I think I need to really let the database do it's job. These buggers were created to handle high volumes of data. Why should I suffer to do it myself again? So i thought I will redo the whole thing in a new DSL approach to queries in a different project altogether. Why not? I am thinking I could jooq after all, and run all the queries I need to perform the analysis in the database itself, split columns into different tables, join on my own IDs, convert currencies, and group a summary by month. I even feel like it will take less time.

#Newer Update
As you can see as per the clients the logic is working fine. I injected the logic into the beans themselves through a couple of visitors and the amounts were easily revalued into revalued amounts and stored into a column I call consamount.<br>
The rawDebits were then easily persisted using jpa and eclipselink into mysql. From there was a bit of a kerfuffle generating a monthlyDebit object list but afer hours of googling and reviewing manuals I was able to extract a list of summary objects using the database itself through JPA. I didn't even touch the jooq. The monthly summaries were then persisted into a different table in the database. Good Job 

#Now
All that is very flowerly, but all that data was not coming from an excel file, as it is intended from the beginning, but was being generated by a faker library. I even added a new module into the library inorder for the lib to do more work. However, migrating that source data from faker to excel is a different thing. <br>
The excel problem is still there, I need to create a list for every sheet of mapped objects. This can be done easily but i was hoping to be able to reuse the package in future,and that's where things get sticky because resusable objects generating programs means expensive data structures, reflection and if you are really smart or you have time to read new manuals, maybe code generation. The thing is hectic and after another whole day of mapping work, the package is not responsive and I am unable to tell where the issue is. I am now not just giving up but looking in FOSS i could use for that. <BR>
I have considered osglworks/excel-reader, but this maps a class to an entire workbook, and that would not do for my 47mb of an excel file. So yeah the progress is slow...

